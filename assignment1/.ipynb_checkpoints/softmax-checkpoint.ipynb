{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.377636\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** -log(1/c), c = number of classes, also can be log(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 3.416446 analytic: 3.416446, relative error: 1.396731e-08\n",
      "numerical: -0.656818 analytic: -0.656818, relative error: 1.227131e-07\n",
      "numerical: 4.586598 analytic: 4.586598, relative error: 1.124714e-08\n",
      "numerical: 2.300981 analytic: 2.300980, relative error: 3.242464e-08\n",
      "numerical: 1.634002 analytic: 1.634002, relative error: 1.320603e-08\n",
      "numerical: 1.731172 analytic: 1.731172, relative error: 1.647834e-08\n",
      "numerical: 0.691241 analytic: 0.691241, relative error: 7.947892e-09\n",
      "numerical: -2.986747 analytic: -2.986747, relative error: 9.582701e-09\n",
      "numerical: 2.299733 analytic: 2.299733, relative error: 1.967523e-09\n",
      "numerical: -0.809245 analytic: -0.809245, relative error: 3.482149e-08\n",
      "numerical: -0.017034 analytic: -0.017379, relative error: 1.000522e-02\n",
      "numerical: 0.298761 analytic: 0.294274, relative error: 7.565173e-03\n",
      "numerical: 0.872895 analytic: 0.870624, relative error: 1.302639e-03\n",
      "numerical: -2.413085 analytic: -2.412400, relative error: 1.420024e-04\n",
      "numerical: 2.182314 analytic: 2.189373, relative error: 1.614698e-03\n",
      "numerical: 2.355319 analytic: 2.349024, relative error: 1.338151e-03\n",
      "numerical: 3.868317 analytic: 3.870357, relative error: 2.637002e-04\n",
      "numerical: -4.188320 analytic: -4.184375, relative error: 4.712206e-04\n",
      "numerical: 4.099730 analytic: 4.095474, relative error: 5.193738e-04\n",
      "numerical: 0.625653 analytic: 0.618022, relative error: 6.135575e-03\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.377636e+00 computed in 0.155086s\n",
      "vectorized loss: 2.377636e+00 computed in 0.006761s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 778.424229\n",
      "iteration 100 / 1500: loss 470.214465\n",
      "iteration 200 / 1500: loss 285.020545\n",
      "iteration 300 / 1500: loss 173.498240\n",
      "iteration 400 / 1500: loss 105.682478\n",
      "iteration 500 / 1500: loss 64.752444\n",
      "iteration 600 / 1500: loss 39.990972\n",
      "iteration 700 / 1500: loss 25.089335\n",
      "iteration 800 / 1500: loss 16.025090\n",
      "iteration 900 / 1500: loss 10.538228\n",
      "iteration 1000 / 1500: loss 7.239583\n",
      "iteration 1100 / 1500: loss 5.244775\n",
      "iteration 1200 / 1500: loss 3.924889\n",
      "iteration 1300 / 1500: loss 3.254284\n",
      "iteration 1400 / 1500: loss 2.820117\n",
      "iteration 0 / 1500: loss 940.352997\n",
      "iteration 100 / 1500: loss 514.830176\n",
      "iteration 200 / 1500: loss 282.694934\n",
      "iteration 300 / 1500: loss 155.629659\n",
      "iteration 400 / 1500: loss 86.187839\n",
      "iteration 500 / 1500: loss 48.077216\n",
      "iteration 600 / 1500: loss 27.197372\n",
      "iteration 700 / 1500: loss 15.861944\n",
      "iteration 800 / 1500: loss 9.679898\n",
      "iteration 900 / 1500: loss 6.147149\n",
      "iteration 1000 / 1500: loss 4.439729\n",
      "iteration 1100 / 1500: loss 3.351842\n",
      "iteration 1200 / 1500: loss 2.792814\n",
      "iteration 1300 / 1500: loss 2.549233\n",
      "iteration 1400 / 1500: loss 2.341206\n",
      "iteration 0 / 1500: loss 1091.187533\n",
      "iteration 100 / 1500: loss 539.693983\n",
      "iteration 200 / 1500: loss 268.183226\n",
      "iteration 300 / 1500: loss 133.736815\n",
      "iteration 400 / 1500: loss 67.252881\n",
      "iteration 500 / 1500: loss 34.420891\n",
      "iteration 600 / 1500: loss 18.082177\n",
      "iteration 700 / 1500: loss 10.021595\n",
      "iteration 800 / 1500: loss 6.011176\n",
      "iteration 900 / 1500: loss 4.096220\n",
      "iteration 1000 / 1500: loss 3.121668\n",
      "iteration 1100 / 1500: loss 2.606421\n",
      "iteration 1200 / 1500: loss 2.424093\n",
      "iteration 1300 / 1500: loss 2.293164\n",
      "iteration 1400 / 1500: loss 2.255474\n",
      "iteration 0 / 1500: loss 1240.522119\n",
      "iteration 100 / 1500: loss 555.375406\n",
      "iteration 200 / 1500: loss 249.752163\n",
      "iteration 300 / 1500: loss 112.888718\n",
      "iteration 400 / 1500: loss 51.704788\n",
      "iteration 500 / 1500: loss 24.338669\n",
      "iteration 600 / 1500: loss 12.140365\n",
      "iteration 700 / 1500: loss 6.567701\n",
      "iteration 800 / 1500: loss 4.139649\n",
      "iteration 900 / 1500: loss 3.089643\n",
      "iteration 1000 / 1500: loss 2.518740\n",
      "iteration 1100 / 1500: loss 2.305995\n",
      "iteration 1200 / 1500: loss 2.291745\n",
      "iteration 1300 / 1500: loss 2.171599\n",
      "iteration 1400 / 1500: loss 2.184014\n",
      "iteration 0 / 1500: loss 1397.143028\n",
      "iteration 100 / 1500: loss 566.031813\n",
      "iteration 200 / 1500: loss 230.338395\n",
      "iteration 300 / 1500: loss 94.522588\n",
      "iteration 400 / 1500: loss 39.535239\n",
      "iteration 500 / 1500: loss 17.297973\n",
      "iteration 600 / 1500: loss 8.276634\n",
      "iteration 700 / 1500: loss 4.594453\n",
      "iteration 800 / 1500: loss 3.072960\n",
      "iteration 900 / 1500: loss 2.596647\n",
      "iteration 1000 / 1500: loss 2.313908\n",
      "iteration 1100 / 1500: loss 2.237250\n",
      "iteration 1200 / 1500: loss 2.222080\n",
      "iteration 1300 / 1500: loss 2.123636\n",
      "iteration 1400 / 1500: loss 2.144539\n",
      "iteration 0 / 1500: loss 1560.317169\n",
      "iteration 100 / 1500: loss 571.915933\n",
      "iteration 200 / 1500: loss 210.588332\n",
      "iteration 300 / 1500: loss 78.456719\n",
      "iteration 400 / 1500: loss 30.070327\n",
      "iteration 500 / 1500: loss 12.363463\n",
      "iteration 600 / 1500: loss 5.887831\n",
      "iteration 700 / 1500: loss 3.556084\n",
      "iteration 800 / 1500: loss 2.713015\n",
      "iteration 900 / 1500: loss 2.348009\n",
      "iteration 1000 / 1500: loss 2.286277\n",
      "iteration 1100 / 1500: loss 2.202694\n",
      "iteration 1200 / 1500: loss 2.250969\n",
      "iteration 1300 / 1500: loss 2.198130\n",
      "iteration 1400 / 1500: loss 2.126860\n",
      "iteration 0 / 1500: loss 783.268887\n",
      "iteration 100 / 1500: loss 286.194015\n",
      "iteration 200 / 1500: loss 105.917500\n",
      "iteration 300 / 1500: loss 40.128787\n",
      "iteration 400 / 1500: loss 16.056097\n",
      "iteration 500 / 1500: loss 7.073894\n",
      "iteration 600 / 1500: loss 3.909586\n",
      "iteration 700 / 1500: loss 2.823407\n",
      "iteration 800 / 1500: loss 2.368302\n",
      "iteration 900 / 1500: loss 2.232457\n",
      "iteration 1000 / 1500: loss 2.146184\n",
      "iteration 1100 / 1500: loss 2.109403\n",
      "iteration 1200 / 1500: loss 2.137788\n",
      "iteration 1300 / 1500: loss 2.139243\n",
      "iteration 1400 / 1500: loss 2.088044\n",
      "iteration 0 / 1500: loss 941.282659\n",
      "iteration 100 / 1500: loss 282.206413\n",
      "iteration 200 / 1500: loss 85.810966\n",
      "iteration 300 / 1500: loss 27.125324\n",
      "iteration 400 / 1500: loss 9.604525\n",
      "iteration 500 / 1500: loss 4.375364\n",
      "iteration 600 / 1500: loss 2.826154\n",
      "iteration 700 / 1500: loss 2.296422\n",
      "iteration 800 / 1500: loss 2.124912\n",
      "iteration 900 / 1500: loss 2.163412\n",
      "iteration 1000 / 1500: loss 2.117724\n",
      "iteration 1100 / 1500: loss 2.145115\n",
      "iteration 1200 / 1500: loss 2.126587\n",
      "iteration 1300 / 1500: loss 2.105657\n",
      "iteration 1400 / 1500: loss 2.143175\n",
      "iteration 0 / 1500: loss 1076.663186\n",
      "iteration 100 / 1500: loss 264.212658\n",
      "iteration 200 / 1500: loss 66.103046\n",
      "iteration 300 / 1500: loss 17.812746\n",
      "iteration 400 / 1500: loss 5.923082\n",
      "iteration 500 / 1500: loss 3.102594\n",
      "iteration 600 / 1500: loss 2.371460\n",
      "iteration 700 / 1500: loss 2.177775\n",
      "iteration 800 / 1500: loss 2.174744\n",
      "iteration 900 / 1500: loss 2.189997\n",
      "iteration 1000 / 1500: loss 2.115751\n",
      "iteration 1100 / 1500: loss 2.089162\n",
      "iteration 1200 / 1500: loss 2.217989\n",
      "iteration 1300 / 1500: loss 2.120935\n",
      "iteration 1400 / 1500: loss 2.136620\n",
      "iteration 0 / 1500: loss 1231.882917\n",
      "iteration 100 / 1500: loss 246.976915\n",
      "iteration 200 / 1500: loss 51.060440\n",
      "iteration 300 / 1500: loss 11.915370\n",
      "iteration 400 / 1500: loss 4.094158\n",
      "iteration 500 / 1500: loss 2.524094\n",
      "iteration 600 / 1500: loss 2.182126\n",
      "iteration 700 / 1500: loss 2.171082\n",
      "iteration 800 / 1500: loss 2.195996\n",
      "iteration 900 / 1500: loss 2.174808\n",
      "iteration 1000 / 1500: loss 2.238318\n",
      "iteration 1100 / 1500: loss 2.209101\n",
      "iteration 1200 / 1500: loss 2.152790\n",
      "iteration 1300 / 1500: loss 2.183549\n",
      "iteration 1400 / 1500: loss 2.174006\n",
      "iteration 0 / 1500: loss 1401.847828\n",
      "iteration 100 / 1500: loss 229.998747\n",
      "iteration 200 / 1500: loss 39.297699\n",
      "iteration 300 / 1500: loss 8.298767\n",
      "iteration 400 / 1500: loss 3.146319\n",
      "iteration 500 / 1500: loss 2.383048\n",
      "iteration 600 / 1500: loss 2.230421\n",
      "iteration 700 / 1500: loss 2.209030\n",
      "iteration 800 / 1500: loss 2.185695\n",
      "iteration 900 / 1500: loss 2.095397\n",
      "iteration 1000 / 1500: loss 2.175285\n",
      "iteration 1100 / 1500: loss 2.088647\n",
      "iteration 1200 / 1500: loss 2.176169\n",
      "iteration 1300 / 1500: loss 2.227713\n",
      "iteration 1400 / 1500: loss 2.152176\n",
      "iteration 0 / 1500: loss 1551.629005\n",
      "iteration 100 / 1500: loss 208.413637\n",
      "iteration 200 / 1500: loss 29.679999\n",
      "iteration 300 / 1500: loss 5.831938\n",
      "iteration 400 / 1500: loss 2.715721\n",
      "iteration 500 / 1500: loss 2.190976\n",
      "iteration 600 / 1500: loss 2.190238\n",
      "iteration 700 / 1500: loss 2.160521\n",
      "iteration 800 / 1500: loss 2.180054\n",
      "iteration 900 / 1500: loss 2.167093\n",
      "iteration 1000 / 1500: loss 2.258784\n",
      "iteration 1100 / 1500: loss 2.160035\n",
      "iteration 1200 / 1500: loss 2.172275\n",
      "iteration 1300 / 1500: loss 2.168551\n",
      "iteration 1400 / 1500: loss 2.159872\n",
      "iteration 0 / 1500: loss 768.959734\n",
      "iteration 100 / 1500: loss 170.591653\n",
      "iteration 200 / 1500: loss 39.237988\n",
      "iteration 300 / 1500: loss 10.322882\n",
      "iteration 400 / 1500: loss 3.845406\n",
      "iteration 500 / 1500: loss 2.557343\n",
      "iteration 600 / 1500: loss 2.129331\n",
      "iteration 700 / 1500: loss 2.064094\n",
      "iteration 800 / 1500: loss 2.088461\n",
      "iteration 900 / 1500: loss 2.171773\n",
      "iteration 1000 / 1500: loss 2.087150\n",
      "iteration 1100 / 1500: loss 1.999075\n",
      "iteration 1200 / 1500: loss 2.018838\n",
      "iteration 1300 / 1500: loss 2.106484\n",
      "iteration 1400 / 1500: loss 2.001712\n",
      "iteration 0 / 1500: loss 938.306353\n",
      "iteration 100 / 1500: loss 154.279985\n",
      "iteration 200 / 1500: loss 26.899772\n",
      "iteration 300 / 1500: loss 6.199884\n",
      "iteration 400 / 1500: loss 2.797355\n",
      "iteration 500 / 1500: loss 2.208406\n",
      "iteration 600 / 1500: loss 2.093980\n",
      "iteration 700 / 1500: loss 2.104222\n",
      "iteration 800 / 1500: loss 2.088394\n",
      "iteration 900 / 1500: loss 2.148065\n",
      "iteration 1000 / 1500: loss 2.181177\n",
      "iteration 1100 / 1500: loss 2.167425\n",
      "iteration 1200 / 1500: loss 2.091042\n",
      "iteration 1300 / 1500: loss 2.053065\n",
      "iteration 1400 / 1500: loss 2.141630\n",
      "iteration 0 / 1500: loss 1078.792783\n",
      "iteration 100 / 1500: loss 131.241124\n",
      "iteration 200 / 1500: loss 17.624039\n",
      "iteration 300 / 1500: loss 4.029292\n",
      "iteration 400 / 1500: loss 2.379853\n",
      "iteration 500 / 1500: loss 2.133791\n",
      "iteration 600 / 1500: loss 2.158730\n",
      "iteration 700 / 1500: loss 2.142694\n",
      "iteration 800 / 1500: loss 2.161524\n",
      "iteration 900 / 1500: loss 2.156861\n",
      "iteration 1000 / 1500: loss 2.113321\n",
      "iteration 1100 / 1500: loss 2.126295\n",
      "iteration 1200 / 1500: loss 2.095919\n",
      "iteration 1300 / 1500: loss 2.139946\n",
      "iteration 1400 / 1500: loss 2.226311\n",
      "iteration 0 / 1500: loss 1225.872662\n",
      "iteration 100 / 1500: loss 110.728465\n",
      "iteration 200 / 1500: loss 11.850678\n",
      "iteration 300 / 1500: loss 3.044889\n",
      "iteration 400 / 1500: loss 2.255476\n",
      "iteration 500 / 1500: loss 2.125864\n",
      "iteration 600 / 1500: loss 2.102523\n",
      "iteration 700 / 1500: loss 2.155577\n",
      "iteration 800 / 1500: loss 2.181350\n",
      "iteration 900 / 1500: loss 2.150889\n",
      "iteration 1000 / 1500: loss 2.142319\n",
      "iteration 1100 / 1500: loss 2.235856\n",
      "iteration 1200 / 1500: loss 2.144890\n",
      "iteration 1300 / 1500: loss 2.202965\n",
      "iteration 1400 / 1500: loss 2.235254\n",
      "iteration 0 / 1500: loss 1383.006625\n",
      "iteration 100 / 1500: loss 92.358357\n",
      "iteration 200 / 1500: loss 8.031252\n",
      "iteration 300 / 1500: loss 2.514971\n",
      "iteration 400 / 1500: loss 2.195942\n",
      "iteration 500 / 1500: loss 2.146478\n",
      "iteration 600 / 1500: loss 2.105589\n",
      "iteration 700 / 1500: loss 2.142771\n",
      "iteration 800 / 1500: loss 2.148201\n",
      "iteration 900 / 1500: loss 2.136108\n",
      "iteration 1000 / 1500: loss 2.135233\n",
      "iteration 1100 / 1500: loss 2.162712\n",
      "iteration 1200 / 1500: loss 2.143260\n",
      "iteration 1300 / 1500: loss 2.113525\n",
      "iteration 1400 / 1500: loss 2.251570\n",
      "iteration 0 / 1500: loss 1532.471482\n",
      "iteration 100 / 1500: loss 76.026175\n",
      "iteration 200 / 1500: loss 5.744957\n",
      "iteration 300 / 1500: loss 2.322775\n",
      "iteration 400 / 1500: loss 2.169408\n",
      "iteration 500 / 1500: loss 2.167016\n",
      "iteration 600 / 1500: loss 2.140479\n",
      "iteration 700 / 1500: loss 2.173857\n",
      "iteration 800 / 1500: loss 2.188934\n",
      "iteration 900 / 1500: loss 2.154059\n",
      "iteration 1000 / 1500: loss 2.182786\n",
      "iteration 1100 / 1500: loss 2.118196\n",
      "iteration 1200 / 1500: loss 2.182525\n",
      "iteration 1300 / 1500: loss 2.167865\n",
      "iteration 1400 / 1500: loss 2.221202\n",
      "iteration 0 / 1500: loss 771.074111\n",
      "iteration 100 / 1500: loss 103.761501\n",
      "iteration 200 / 1500: loss 15.615324\n",
      "iteration 300 / 1500: loss 3.955001\n",
      "iteration 400 / 1500: loss 2.367981\n",
      "iteration 500 / 1500: loss 2.166648\n",
      "iteration 600 / 1500: loss 2.124585\n",
      "iteration 700 / 1500: loss 2.198611\n",
      "iteration 800 / 1500: loss 2.134964\n",
      "iteration 900 / 1500: loss 2.068524\n",
      "iteration 1000 / 1500: loss 2.129437\n",
      "iteration 1100 / 1500: loss 2.144447\n",
      "iteration 1200 / 1500: loss 2.148788\n",
      "iteration 1300 / 1500: loss 2.111501\n",
      "iteration 1400 / 1500: loss 2.120006\n",
      "iteration 0 / 1500: loss 929.699112\n",
      "iteration 100 / 1500: loss 84.124419\n",
      "iteration 200 / 1500: loss 9.404476\n",
      "iteration 300 / 1500: loss 2.729420\n",
      "iteration 400 / 1500: loss 2.233590\n",
      "iteration 500 / 1500: loss 2.111278\n",
      "iteration 600 / 1500: loss 2.060254\n",
      "iteration 700 / 1500: loss 2.093283\n",
      "iteration 800 / 1500: loss 2.161991\n",
      "iteration 900 / 1500: loss 2.073695\n",
      "iteration 1000 / 1500: loss 2.179236\n",
      "iteration 1100 / 1500: loss 2.172848\n",
      "iteration 1200 / 1500: loss 2.165173\n",
      "iteration 1300 / 1500: loss 2.127862\n",
      "iteration 1400 / 1500: loss 2.141727\n",
      "iteration 0 / 1500: loss 1091.058577\n",
      "iteration 100 / 1500: loss 66.457406\n",
      "iteration 200 / 1500: loss 5.930161\n",
      "iteration 300 / 1500: loss 2.454218\n",
      "iteration 400 / 1500: loss 2.176091\n",
      "iteration 500 / 1500: loss 2.125616\n",
      "iteration 600 / 1500: loss 2.144825\n",
      "iteration 700 / 1500: loss 2.177695\n",
      "iteration 800 / 1500: loss 2.108495\n",
      "iteration 900 / 1500: loss 2.204108\n",
      "iteration 1000 / 1500: loss 2.096365\n",
      "iteration 1100 / 1500: loss 2.135763\n",
      "iteration 1200 / 1500: loss 2.188886\n",
      "iteration 1300 / 1500: loss 2.122353\n",
      "iteration 1400 / 1500: loss 2.148907\n",
      "iteration 0 / 1500: loss 1250.925241\n",
      "iteration 100 / 1500: loss 51.150468\n",
      "iteration 200 / 1500: loss 4.133668\n",
      "iteration 300 / 1500: loss 2.235345\n",
      "iteration 400 / 1500: loss 2.071045\n",
      "iteration 500 / 1500: loss 2.137014\n",
      "iteration 600 / 1500: loss 2.085878\n",
      "iteration 700 / 1500: loss 2.200224\n",
      "iteration 800 / 1500: loss 2.145795\n",
      "iteration 900 / 1500: loss 2.136712\n",
      "iteration 1000 / 1500: loss 2.163983\n",
      "iteration 1100 / 1500: loss 2.177941\n",
      "iteration 1200 / 1500: loss 2.151195\n",
      "iteration 1300 / 1500: loss 2.138341\n",
      "iteration 1400 / 1500: loss 2.123307\n",
      "iteration 0 / 1500: loss 1375.156190\n",
      "iteration 100 / 1500: loss 38.123065\n",
      "iteration 200 / 1500: loss 3.158172\n",
      "iteration 300 / 1500: loss 2.216531\n",
      "iteration 400 / 1500: loss 2.139567\n",
      "iteration 500 / 1500: loss 2.139849\n",
      "iteration 600 / 1500: loss 2.183952\n",
      "iteration 700 / 1500: loss 2.197310\n",
      "iteration 800 / 1500: loss 2.170614\n",
      "iteration 900 / 1500: loss 2.166061\n",
      "iteration 1000 / 1500: loss 2.158156\n",
      "iteration 1100 / 1500: loss 2.221295\n",
      "iteration 1200 / 1500: loss 2.129906\n",
      "iteration 1300 / 1500: loss 2.178668\n",
      "iteration 1400 / 1500: loss 2.158270\n",
      "iteration 0 / 1500: loss 1531.949052\n",
      "iteration 100 / 1500: loss 28.822196\n",
      "iteration 200 / 1500: loss 2.601222\n",
      "iteration 300 / 1500: loss 2.151082\n",
      "iteration 400 / 1500: loss 2.170149\n",
      "iteration 500 / 1500: loss 2.207526\n",
      "iteration 600 / 1500: loss 2.202009\n",
      "iteration 700 / 1500: loss 2.149953\n",
      "iteration 800 / 1500: loss 2.187762\n",
      "iteration 900 / 1500: loss 2.166270\n",
      "iteration 1000 / 1500: loss 2.179858\n",
      "iteration 1100 / 1500: loss 2.124321\n",
      "iteration 1200 / 1500: loss 2.199781\n",
      "iteration 1300 / 1500: loss 2.257230\n",
      "iteration 1400 / 1500: loss 2.132514\n",
      "iteration 0 / 1500: loss 768.522325\n",
      "iteration 100 / 1500: loss 63.228946\n",
      "iteration 200 / 1500: loss 7.005491\n",
      "iteration 300 / 1500: loss 2.488425\n",
      "iteration 400 / 1500: loss 2.219062\n",
      "iteration 500 / 1500: loss 2.105528\n",
      "iteration 600 / 1500: loss 2.060257\n",
      "iteration 700 / 1500: loss 2.119737\n",
      "iteration 800 / 1500: loss 2.116208\n",
      "iteration 900 / 1500: loss 2.113581\n",
      "iteration 1000 / 1500: loss 2.148470\n",
      "iteration 1100 / 1500: loss 2.177463\n",
      "iteration 1200 / 1500: loss 2.144371\n",
      "iteration 1300 / 1500: loss 2.149091\n",
      "iteration 1400 / 1500: loss 2.013898\n",
      "iteration 0 / 1500: loss 931.181292\n",
      "iteration 100 / 1500: loss 46.734383\n",
      "iteration 200 / 1500: loss 4.277757\n",
      "iteration 300 / 1500: loss 2.310663\n",
      "iteration 400 / 1500: loss 2.095477\n",
      "iteration 500 / 1500: loss 2.181467\n",
      "iteration 600 / 1500: loss 2.167032\n",
      "iteration 700 / 1500: loss 2.185422\n",
      "iteration 800 / 1500: loss 2.134476\n",
      "iteration 900 / 1500: loss 2.104845\n",
      "iteration 1000 / 1500: loss 2.143011\n",
      "iteration 1100 / 1500: loss 2.150505\n",
      "iteration 1200 / 1500: loss 2.142201\n",
      "iteration 1300 / 1500: loss 2.146664\n",
      "iteration 1400 / 1500: loss 2.040209\n",
      "iteration 0 / 1500: loss 1055.547715\n",
      "iteration 100 / 1500: loss 32.607044\n",
      "iteration 200 / 1500: loss 3.044420\n",
      "iteration 300 / 1500: loss 2.114732\n",
      "iteration 400 / 1500: loss 2.155488\n",
      "iteration 500 / 1500: loss 2.143928\n",
      "iteration 600 / 1500: loss 2.186921\n",
      "iteration 700 / 1500: loss 2.166974\n",
      "iteration 800 / 1500: loss 2.155511\n",
      "iteration 900 / 1500: loss 2.187483\n",
      "iteration 1000 / 1500: loss 2.095336\n",
      "iteration 1100 / 1500: loss 2.188044\n",
      "iteration 1200 / 1500: loss 2.071819\n",
      "iteration 1300 / 1500: loss 2.148318\n",
      "iteration 1400 / 1500: loss 2.175620\n",
      "iteration 0 / 1500: loss 1231.589667\n",
      "iteration 100 / 1500: loss 23.508249\n",
      "iteration 200 / 1500: loss 2.556754\n",
      "iteration 300 / 1500: loss 2.164144\n",
      "iteration 400 / 1500: loss 2.144827\n",
      "iteration 500 / 1500: loss 2.168159\n",
      "iteration 600 / 1500: loss 2.184948\n",
      "iteration 700 / 1500: loss 2.186244\n",
      "iteration 800 / 1500: loss 2.222007\n",
      "iteration 900 / 1500: loss 2.175707\n",
      "iteration 1000 / 1500: loss 2.161199\n",
      "iteration 1100 / 1500: loss 2.112768\n",
      "iteration 1200 / 1500: loss 2.189428\n",
      "iteration 1300 / 1500: loss 2.125632\n",
      "iteration 1400 / 1500: loss 2.168591\n",
      "iteration 0 / 1500: loss 1384.311515\n",
      "iteration 100 / 1500: loss 16.601288\n",
      "iteration 200 / 1500: loss 2.260472\n",
      "iteration 300 / 1500: loss 2.222189\n",
      "iteration 400 / 1500: loss 2.202204\n",
      "iteration 500 / 1500: loss 2.151962\n",
      "iteration 600 / 1500: loss 2.127143\n",
      "iteration 700 / 1500: loss 2.127895\n",
      "iteration 800 / 1500: loss 2.101256\n",
      "iteration 900 / 1500: loss 2.164819\n",
      "iteration 1000 / 1500: loss 2.172690\n",
      "iteration 1100 / 1500: loss 2.158906\n",
      "iteration 1200 / 1500: loss 2.137823\n",
      "iteration 1300 / 1500: loss 2.153568\n",
      "iteration 1400 / 1500: loss 2.170066\n",
      "iteration 0 / 1500: loss 1552.684853\n",
      "iteration 100 / 1500: loss 11.884048\n",
      "iteration 200 / 1500: loss 2.223269\n",
      "iteration 300 / 1500: loss 2.172638\n",
      "iteration 400 / 1500: loss 2.252632\n",
      "iteration 500 / 1500: loss 2.158226\n",
      "iteration 600 / 1500: loss 2.182445\n",
      "iteration 700 / 1500: loss 2.194799\n",
      "iteration 800 / 1500: loss 2.232131\n",
      "iteration 900 / 1500: loss 2.176656\n",
      "iteration 1000 / 1500: loss 2.185394\n",
      "iteration 1100 / 1500: loss 2.158058\n",
      "iteration 1200 / 1500: loss 2.155375\n",
      "iteration 1300 / 1500: loss 2.232041\n",
      "iteration 1400 / 1500: loss 2.189181\n",
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.350694 val accuracy: 0.360000\n",
      "lr 1.000000e-07 reg 3.000000e+04 train accuracy: 0.342204 val accuracy: 0.356000\n",
      "lr 1.000000e-07 reg 3.500000e+04 train accuracy: 0.340082 val accuracy: 0.355000\n",
      "lr 1.000000e-07 reg 4.000000e+04 train accuracy: 0.333286 val accuracy: 0.354000\n",
      "lr 1.000000e-07 reg 4.500000e+04 train accuracy: 0.332388 val accuracy: 0.347000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.330939 val accuracy: 0.343000\n",
      "lr 2.000000e-07 reg 2.500000e+04 train accuracy: 0.351592 val accuracy: 0.374000\n",
      "lr 2.000000e-07 reg 3.000000e+04 train accuracy: 0.338878 val accuracy: 0.355000\n",
      "lr 2.000000e-07 reg 3.500000e+04 train accuracy: 0.335245 val accuracy: 0.347000\n",
      "lr 2.000000e-07 reg 4.000000e+04 train accuracy: 0.333020 val accuracy: 0.349000\n",
      "lr 2.000000e-07 reg 4.500000e+04 train accuracy: 0.328510 val accuracy: 0.339000\n",
      "lr 2.000000e-07 reg 5.000000e+04 train accuracy: 0.326939 val accuracy: 0.352000\n",
      "lr 3.000000e-07 reg 2.500000e+04 train accuracy: 0.339367 val accuracy: 0.346000\n",
      "lr 3.000000e-07 reg 3.000000e+04 train accuracy: 0.347837 val accuracy: 0.356000\n",
      "lr 3.000000e-07 reg 3.500000e+04 train accuracy: 0.325531 val accuracy: 0.344000\n",
      "lr 3.000000e-07 reg 4.000000e+04 train accuracy: 0.332694 val accuracy: 0.352000\n",
      "lr 3.000000e-07 reg 4.500000e+04 train accuracy: 0.329673 val accuracy: 0.348000\n",
      "lr 3.000000e-07 reg 5.000000e+04 train accuracy: 0.328878 val accuracy: 0.340000\n",
      "lr 4.000000e-07 reg 2.500000e+04 train accuracy: 0.350449 val accuracy: 0.359000\n",
      "lr 4.000000e-07 reg 3.000000e+04 train accuracy: 0.342714 val accuracy: 0.364000\n",
      "lr 4.000000e-07 reg 3.500000e+04 train accuracy: 0.335918 val accuracy: 0.348000\n",
      "lr 4.000000e-07 reg 4.000000e+04 train accuracy: 0.327980 val accuracy: 0.336000\n",
      "lr 4.000000e-07 reg 4.500000e+04 train accuracy: 0.326163 val accuracy: 0.345000\n",
      "lr 4.000000e-07 reg 5.000000e+04 train accuracy: 0.325939 val accuracy: 0.344000\n",
      "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.350347 val accuracy: 0.366000\n",
      "lr 5.000000e-07 reg 3.000000e+04 train accuracy: 0.340633 val accuracy: 0.359000\n",
      "lr 5.000000e-07 reg 3.500000e+04 train accuracy: 0.329490 val accuracy: 0.354000\n",
      "lr 5.000000e-07 reg 4.000000e+04 train accuracy: 0.340306 val accuracy: 0.352000\n",
      "lr 5.000000e-07 reg 4.500000e+04 train accuracy: 0.328367 val accuracy: 0.329000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.331776 val accuracy: 0.337000\n",
      "best validation accuracy achieved during cross-validation: 0.374000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "# Your code\n",
    "\n",
    "for lr in [learning_rates[0], learning_rates[0] * 2, learning_rates[0] * 3, learning_rates[0] * 4, learning_rates[1]]:\n",
    "    for reg in range(int(regularization_strengths[0]), int(regularization_strengths[1]) + 5000, 5000):\n",
    "        \n",
    "        softmax = Softmax()\n",
    "        loss_hist = softmax.train(X_train, y_train, learning_rate=lr, reg=reg, num_iters=1500, verbose=True)\n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        \n",
    "        train_accuracy = np.mean(y_train == y_train_pred)\n",
    "        val_accuracy = np.mean(y_val == y_val_pred)\n",
    "        \n",
    "        results[(lr, reg)] = train_accuracy, val_accuracy\n",
    "        if val_accuracy > best_val:\n",
    "            best_val = val_accuracy\n",
    "            best_softmax = softmax\n",
    "            \n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.369000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline Question** - *True or False*\n",
    "\n",
    "It's possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "*Your answer*: true\n",
    "\n",
    "*Your explanation*: if the new datapoint is classified correctly and have a numch higher score than other classes, the SVM loss would be 0, but the Softmax would still have a loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAF8CAYAAADrUz6WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngXiZCgQCgUAgELgD/wvBkv++rqnxfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1000x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
